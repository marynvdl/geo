{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely.geometry\n",
    "import shapely.ops\n",
    "import pandas as pd\n",
    "import folium\n",
    "import earthpy\n",
    "from ipyleaflet import Map, GeoData, basemaps, LayersControl\n",
    "import json\n",
    "from ipywidgets import HTML\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import time\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buffering parks and clipping rivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "parks = gpd.read_file(\"../../data/rivers/Polygon_layer.shp\").to_crs(epsg=4269)\n",
    "\n",
    "\n",
    "for index, park in parks.iterrows():\n",
    "    print(park.loc['name'])\n",
    "\n",
    "\n",
    "park_name = 'Eastern CAR Wilderness - no settlements no agriculture - 102\\'000 km2'\n",
    "\n",
    "\n",
    "# Buffer\n",
    "park_buffer = parks.loc[parks['name'] == park_name].to_crs('+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs ')\n",
    "\n",
    "park_buffer['geometry'] = park_buffer['geometry'].geometry.buffer(500000)\n",
    "park_buffer = park_buffer.to_crs(epsg=4269)\n",
    "\n",
    "# Park\n",
    "park = parks.loc[parks['name'] == park_name].to_crs('+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs ')\n",
    "park['geometry'] = park['geometry'].geometry.buffer(3000)\n",
    "\n",
    "park = park.to_crs(epsg=4269)\n",
    "\n",
    "# Rivers\n",
    "try:\n",
    "    rwa_rivers\n",
    "except NameError:\n",
    "    rwa_rivers = gpd.read_file(\"../../data/rivers/clipped_rivers.shp\").to_crs(epsg=4269)\n",
    "\n",
    "# Buffer rivers\n",
    "buffer_border = gpd.GeoDataFrame(geometry=park_buffer.boundary)\n",
    "buffer_rivers = gpd.sjoin(rwa_rivers, park_buffer, how='inner', predicate='within')\n",
    "\n",
    "# Park rivers\n",
    "park_rivers = gpd.sjoin(rwa_rivers, park, how='inner', predicate='within')\n",
    "\n",
    "park_rivers = park_rivers.reset_index(drop=True)\n",
    "\n",
    "# Set property if in park\n",
    "buffer_rivers['in_park'] = 0\n",
    "for index1, river1 in buffer_rivers.iterrows():\n",
    "    if river1['NOID'] in park_rivers['NOID'].values:\n",
    "        buffer_rivers.at[index1, 'in_park'] = 1\n",
    "        \n",
    "buffer_rivers = buffer_rivers.rename(columns={'index_left': 'i_l'})\n",
    "buffer_rivers = buffer_rivers.rename(columns={'index_right': 'i_r'})\n",
    "buffer_rivers = buffer_rivers.reset_index(drop=True)\n",
    "\n",
    "buffer_rivers['park_dis']=0.0\n",
    "buffer_rivers['calc_dis']=0.0\n",
    "buffer_rivers['up_dis']=0.0\n",
    "buffer_rivers['ran']=0\n",
    "buffer_rivers['in_ran']=0\n",
    "\n",
    "buffer_rivers['start_dis']=0.0\n",
    "buffer_rivers['outside_dis']=0.0\n",
    "buffer_rivers['enters_park'] = 0\n",
    "buffer_rivers['inflow']=0\n",
    "buffer_rivers['through_flow']=0\n",
    "\n",
    "# Rivers on boundary of park\n",
    "buffer_rivers['intersect_park'] = 0\n",
    "park_rivers['intersect_park'] = 0\n",
    "park_rivers['outside_dis']=0.0\n",
    "\n",
    "park_border = gpd.GeoDataFrame(geometry=park.boundary)\n",
    "all_inters = gpd.sjoin(buffer_rivers, park_border, op='intersects')\n",
    "\n",
    "\n",
    "\n",
    "for index1, river1 in buffer_rivers.iterrows():\n",
    "    if river1['NOID'] in all_inters['NOID'].values:\n",
    "        buffer_rivers.at[index1, 'intersect_park'] = 1\n",
    "        buffer_rivers.at[index1, 'in_park'] = 1\n",
    "\n",
    "for index1, river1 in buffer_rivers.iterrows():\n",
    "    if river1['NOID'] in park_rivers['NOID'].values:\n",
    "        buffer_rivers.at[index1, 'in_park'] = 1\n",
    "        \n",
    "\n",
    "for index1, river1 in all_inters.iterrows():\n",
    "    if river1['NOID'] in park_rivers['NOID'].values:\n",
    "        park_rivers.at[index1, 'intersect_park'] = 1  \n",
    "        \n",
    "\n",
    "all_inters = all_inters.reset_index(drop=True)        \n",
    "inters = gpd.GeoDataFrame()\n",
    "for index1, r1 in all_inters.iterrows():\n",
    "    already_intersected = 0\n",
    "    for index2, r2 in all_inters.iterrows():\n",
    "        if r1['NOID'] == r2['NDOID']:\n",
    "            already_intersected = 1\n",
    "    if already_intersected != 1:\n",
    "        inters = inters.append(all_inters.iloc[index1])\n",
    "            \n",
    "# Make df of all rivers inside and intersecting park\n",
    "in_park = park_rivers.append(inters)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_aspect('equal')\n",
    "buffer_rivers.plot(ax=ax, color='grey')\n",
    "park_border.plot(ax=ax, color='red')\n",
    "in_park.plot(ax=ax, color='orange')\n",
    "\n",
    "# inters.plot(ax=ax, color='blue')\n",
    "plt.show();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find upstream river outside park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "in_inters = gpd.GeoDataFrame()\n",
    "inters = inters.reset_index(drop=True)\n",
    "\n",
    "# Loop through all rivers intersecting with park border\n",
    "for index1, r1 in inters.iterrows():\n",
    "    # All rivers starting\n",
    "    if r1['NUOID'] is None:\n",
    "        pass\n",
    "    # All rivers not starting\n",
    "    else:\n",
    "        for index2, r2 in buffer_rivers.loc[buffer_rivers['NDOID']==r1['NOID']].iterrows():\n",
    "            # If river (r2) flows into river on border (r1)\n",
    "            if r1['NOID'] == r2['NDOID']:\n",
    "                # to make sure upstream river (r2) is outside the park\n",
    "                if r2['in_park'] != 1:\n",
    "                    # then upstream river (r2) is flowing into the park\n",
    "                    r1['inflow'] = 1\n",
    "                    in_inters = in_inters.append(inters.iloc[index1])\n",
    "                    \n",
    "            if r1['NOID'] == r2['NOID']:\n",
    "                buffer_rivers.at[index2, 'inflow'] = 1\n",
    "\n",
    "\n",
    "if in_inters.shape[0] > 0:                \n",
    "\n",
    "    # drop all duplicate in-flowing rivers\n",
    "    in_inters = in_inters.drop_duplicates()\n",
    "    print('Number of inflowing rivers: ' + str(len(in_inters)))\n",
    "\n",
    "    # set property on buffer_rivers to know that river is entering the park from outside\n",
    "    for index1, river1 in buffer_rivers.iterrows():\n",
    "        if river1['NOID'] in in_inters['NOID'].values:\n",
    "            buffer_rivers.at[index1, 'enters_park'] = 1  \n",
    "\n",
    "    # plot to show in-flowing rivers\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_aspect('equal')\n",
    "    park_border.plot(ax=ax, color='grey')\n",
    "    park_rivers.plot(ax=ax, color='black')\n",
    "    inters.plot(ax=ax, color='blue')\n",
    "    in_inters.plot(ax=ax, color='red')\n",
    "    plt.show();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating outside flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if in_inters.shape[0] > 0:                \n",
    "\n",
    "    for index1, r1 in in_inters.iterrows(): \n",
    "        print(\"\\n\")\n",
    "        print(r1['NOID'])\n",
    "        print('start_flow: ' + str(r1['DIS_AV_CMS'] ))\n",
    "\n",
    "\n",
    "        run = 0\n",
    "        # If the river has reached the park boundary and is now flowing out\n",
    "        out_flow = 0\n",
    "        new_inters = gpd.GeoDataFrame()\n",
    "\n",
    "        # While the river is still inside the park\n",
    "        while out_flow == 0:\n",
    "            run += 1\n",
    "            print('run' + str(run))\n",
    "            # If in-flowing rivers on park boundary\n",
    "            if run == 1:\n",
    "                for index2, r2 in buffer_rivers.loc[buffer_rivers['NOID']==r1['NDOID']].iterrows():\n",
    "                    # If inflowing river (r1) is flowing into downstream river (r2)\n",
    "                    if r1['NDOID'] == r2['NOID']:\n",
    "\n",
    "                        # Set the downstream river (r2)'s outside flow to the inflowing river (r1)'s flow\n",
    "                        buffer_rivers.at[index2, 'outside_dis'] = r2['outside_dis']  + r1['DIS_AV_CMS']\n",
    "\n",
    "                        # Mark r2 as flowing through the park\n",
    "                        buffer_rivers.at[index2, 'through_flow'] = 1\n",
    "                        # Add r2 to become the next round's upstream river\n",
    "                        new_inters = new_inters.append(buffer_rivers.iloc[index2])\n",
    "                        # Check if r2 is already crossing the park boundary (leaving the park)\n",
    "                        if r2['in_park'] == 0:\n",
    "                            out_flow = 1\n",
    "\n",
    "            # If not the in-flowing river, but a next-in-line downstream river\n",
    "\n",
    "            else:\n",
    "                for index3, r3 in new_inters.iterrows():\n",
    "                    new_inters = gpd.GeoDataFrame()\n",
    "                    for index4, r4 in buffer_rivers.loc[buffer_rivers['NOID']==r3['NDOID']].iterrows():\n",
    "                        # If upstream river (r3) is flowing into downstream river (r4)                    \n",
    "                        if r3['NDOID'] == r4['NOID']:\n",
    "                            buffer_rivers.at[index4, 'outside_dis'] = r4['outside_dis']  + r1['DIS_AV_CMS']\n",
    "\n",
    "                            buffer_rivers.at[index4, 'through_flow'] = 1\n",
    "                            new_inters = new_inters.append(buffer_rivers.iloc[index4])\n",
    "                            if r4['in_park'] == 0:\n",
    "                                out_flow = 1                       \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate park contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for index1, r1 in buffer_rivers.iterrows():\n",
    "    if r1['outside_dis'] != 0:\n",
    "        buffer_rivers.at[index1, 'park_dis'] = r1['DIS_AV_CMS'] - r1['outside_dis']\n",
    "        buffer_rivers.at[index1, 'calc_dis'] = (r1['DIS_AV_CMS'] - r1['outside_dis'])/r1['DIS_AV_CMS']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine with rivers starting inside park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all rivers intersecting with park border\n",
    "for index1, r1 in inters.iterrows():\n",
    "#     buffer_rivers = buffer_rivers.reset_index()\n",
    "    buffer_rivers['ran']=0\n",
    "    buffer_rivers['up_dis']=0.0\n",
    "    inters['start_dis']=inters['DIS_AV_CMS']\n",
    "    buffer_rivers['start_dis']=0.0 \n",
    "    \n",
    "    # All rivers starting\n",
    "    if r1['NUOID'] is None:\n",
    "        buffer_rivers['calc_p']=0.0\n",
    "\n",
    "# If inter set buffer_rivers to 1\n",
    "for index1, r1 in inters.iterrows():    \n",
    "    for index2, r2 in buffer_rivers.loc[buffer_rivers['NOID']==r1['NOID']].iterrows():\n",
    "        if r1['NOID'] == r2['NOID'] and r2['enters_park'] == 0:\n",
    "            buffer_rivers.at[index2, 'calc_p'] = 1\n",
    "    for index2, r2 in buffer_rivers.loc[buffer_rivers['NOID']==r1['NDOID']].iterrows():        \n",
    "        if (r1['NDOID'] == r2['NOID']) and (r1['NUOID'] is None):\n",
    "            buffer_rivers.at[index2, 'start_dis'] = r2['start_dis'] + r1['DIS_AV_CMS']\n",
    "\n",
    "# Set start dis from river flowing out of park\n",
    "# for index1, r1 in inters.iterrows():\n",
    "#     for index2, r2 in buffer_rivers.loc[buffer_rivers['NOID']==r1['NOID']].iterrows():\n",
    "#         if r1['NDOID'] == r2['NOID']:\n",
    "#             inters.at[index1, 'start_dis'] = r2['start_dis']          \n",
    "            \n",
    "new_inters = inters\n",
    "print(inters.shape[0])\n",
    "runs = 500\n",
    "run = 0\n",
    "while run < 100:\n",
    "    run += 1\n",
    "    print(str(round(run*100/runs)))\n",
    "    new_new_inters = new_inters\n",
    "    new_inters = gpd.GeoDataFrame()\n",
    "    for index3, r3 in new_new_inters.iterrows():\n",
    "\n",
    "        \n",
    "        if r3['NUOID'] is None:\n",
    "            buffer_rivers.loc[buffer_rivers['NOID']==r3['NOID'],'start_dis'] = r3['DIS_AV_CMS']            \n",
    "\n",
    "        else:\n",
    "\n",
    "            upstream_ids = map(int, r3['NUOID'].split('_'))                \n",
    "            upstream = buffer_rivers.loc[buffer_rivers['NOID'].isin(upstream_ids)].reset_index()\n",
    "\n",
    "            buffer_rivers.at[index3, 'start_dis'] = upstream['start_dis'].sum()\n",
    "            if r4['calc_dis'] == 0:\n",
    "                buffer_rivers.at[index3, 'park_dis'] = upstream['park_dis'].sum()\n",
    "\n",
    "        for index4, r4 in buffer_rivers.loc[buffer_rivers['NOID']==r3['NDOID']].iterrows():\n",
    "                if (r3['NDOID'] == r4['NOID']):\n",
    "\n",
    "#                     if buffer_rivers.at[index4, 'outside_dis'] == 0:\n",
    "#                         buffer_rivers.at[index4, 'outside_dis'] = r3['outside_dis']\n",
    "\n",
    "#                     if r4['calc_dis'] == 0:\n",
    "#                         buffer_rivers.at[index4, 'park_dis'] = r3['park_dis']\n",
    "#                         buffer_rivers.at[index4, 'calc_dis'] = r3['calc_dis'] + buffer_rivers.at[index4, 'calc_dis']\n",
    "\n",
    "\n",
    "#                     buffer_rivers.at[index4, 'calc_p'] = round(buffer_rivers.at[index4, 'start_dis']/r4['DIS_AV_CMS'],4)\n",
    "\n",
    "                    new_inters = new_inters.append(buffer_rivers.iloc[index4])\n",
    "                    \n",
    "\n",
    "# def calc_park_dis(row):\n",
    "#     if row['outside_dis'] > 0:\n",
    "#         park_dis = row['DIS_AV_CMS'] - row['outside_dis']\n",
    "#     else:\n",
    "#         park_dis = 0\n",
    "#     return park_dis\n",
    "\n",
    "    \n",
    "# buffer_rivers['park_dis'] = buffer_rivers.apply(calc_park_dis, axis=1)\n",
    "# print(buffer_rivers.head())\n",
    "\n",
    "buffer_rivers['calc_dis'] = buffer_rivers['park_dis']/buffer_rivers['DIS_AV_CMS']\n",
    "\n",
    "buffer_rivers['calc_p'] = buffer_rivers['calc_p'] + buffer_rivers['calc_dis']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "buffer_rivers['calc_dis'] = buffer_rivers['park_dis']/buffer_rivers['DIS_AV_CMS']\n",
    "buffer_rivers['calc_p'] = (buffer_rivers['start_dis']/buffer_rivers['DIS_AV_CMS'])+ buffer_rivers['calc_dis']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# for index1, r1 in buffer_rivers.iterrows():\n",
    "#     if buffer_rivers.at[index1, 'in_park'] == 1 and buffer_rivers.at[index1, 'through_flow'] != 1 and buffer_rivers.at[index1, 'enters_park'] == 0:\n",
    "#         buffer_rivers.at[index1, 'calc_p'] = 1\n",
    "#     if buffer_rivers.at[index1, 'park_dis'] < 0:\n",
    "#         buffer_rivers.at[index1, 'park_dis'] = 0\n",
    "#         buffer_rivers.at[index1, 'calc_p'] = 0  \n",
    "\n",
    "# relevant_rivers = buffer_rivers.loc[buffer_rivers['calc_p'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "relevant_rivers = buffer_rivers.loc[buffer_rivers['calc_p'] > 0]\n",
    "m = folium.Map([park.centroid.y, park.centroid.x],\n",
    "                  zoom_start=10,\n",
    "                  tiles='Stamen Terrain')\n",
    "\n",
    "def create_cols(dis):\n",
    "    if dis < 0.1:\n",
    "        col = '#3e5946'\n",
    "    else:\n",
    "        col = '#34278f'\n",
    "    return col\n",
    "\n",
    "relevant_rivers['col'] = pd.cut(relevant_rivers['calc_p'], bins=5, labels=['white', '#73a4af', '#4f84a2', '#253c5e', '#182749'])\n",
    "\n",
    "\n",
    "gj = folium.GeoJson(\n",
    "    relevant_rivers,\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': feature['properties']['col'],\n",
    "        'color' : feature['properties']['col'],\n",
    "        'weight' : 3,\n",
    "        'fillOpacity' : 0.5,\n",
    "        },\n",
    "    popup=folium.GeoJsonPopup(fields=['NOID', 'NDOID', 'NUOID', 'through_flow', 'in_park', 'park_dis', 'calc_p', 'calc_dis', 'start_dis', 'DIS_AV_CMS', 'outside_dis'])\n",
    "    )\n",
    "\n",
    "park_plot = folium.GeoJson(\n",
    "    park,\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': 'red',\n",
    "        'color' : 'red',\n",
    "        'weight' : 3,\n",
    "        'fillOpacity' : 0.5,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "park_plot.add_to(m)\n",
    "gj.add_to(m)\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
